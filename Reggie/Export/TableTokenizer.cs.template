<%
var rules = (IList<LexRule>)Arguments["rules"];
var ignoreCase = (bool)Arguments["ignorecase"];
var lineCounted = (bool)Arguments["lines"];
var inputFile = (string)Arguments["inputfile"];
var outputFile = (string)Arguments["outputfile"];
var stderr = (TextWriter)Arguments["stderr"];
var codeclass = (string)Arguments["codeclass"];
var dot = (bool)Arguments["dot"];
var jpg = (bool)Arguments["jpg"];
var cwd = Path.GetDirectoryName(outputFile!=null?outputFile:inputFile);
var blockEnds = BuildBlockEnds(rules,inputFile,ignoreCase);
var symbolTable = BuildSymbolTable(rules);
var symbolFlags = BuildSymbolFlags(rules);
var lexer = BuildLexer(rules,inputFile,ignoreCase);
if(dot) {
    var opts = new F.FFA.DotGraphOptions();
    var fn = Path.Combine(cwd, codeclass + ".dot");
    stderr.WriteLine("Writing {0}...",fn);
    using(var sw=new StreamWriter(fn)) {
        lexer.WriteDotTo(sw,opts);
    }        
}
if(jpg) {
    var opts = new F.FFA.DotGraphOptions();
    var fn = Path.Combine(cwd, codeclass + ".jpg");
    stderr.WriteLine("Writing {0}...",fn);
    lexer.RenderToFile(fn,opts);
}
%>
/// <summary>Represents a single token in a tokenized input stream</summary>
public struct Token
{
    /// <summary>Indicates the accepted symbol id</summary>
    public int Id { get; }
    /// <summary>Indicates the captured value</summary>
    public string Value { get; }
    /// <summary>Indicates the position within the stream</summary>
    public long Position { get; }
<%  if (lineCounted) {%>
    /// <summary>Indicates the line number within the stream</summary>
    public int Line { get; }
    /// <summary>Indicates the column number within the stream</summary>
    public int Column { get; }
<% } %>
    /// <summary>Constructs a new instance of a token</summary>
    /// <param name="id">The symbol id</param>
    /// <param name="value">The captured value</param>
    /// <param name="position">The position</param>
<%  if (lineCounted) {%>
    /// <param name="line">The line</param>
    /// <param name="column">The column</param>
    public Token(int id, string value, long position, int line, int column) {
<% } else { %>
    public Token(int id, string value, long position) {
<% } %>
        Id = id;
        Value = value;
        Position = position;
<%  if (lineCounted) {%>
        Line = line;
        Column = column;
<% } %>
    }
}
/// <summary>Indicates the id of the #ERROR symbol</summary>
public const int ERROR = -1;
<%
for(var i = 0;i<symbolTable.Length;++i) {
if(!string.IsNullOrEmpty(symbolTable[i])) {
%>
/// <summary>Indicates the id of the <%=symbolTable[i]%> symbol</summary>
public const int <%=symbolTable[i]%> = <%=i%>;
<%}}%>

<% for(var k = 0;k<2;++k) { 
bool reader = k==1;
string curtype = reader ? "System.IO.TextReader":"System.Collections.Generic.IEnumerator<char>";
string curname = reader ? "text":"cursor";
string texttype = reader ? "System.IO.TextReader":"System.Collections.Generic.IEnumerable<char>";

%>
/// <summary>Lexes tokens off of an input stream</summary>
/// <param name="text">The text to tokenize</param>
/// <param name="position">The starting position</param>
<% if(lineCounted) {%>
/// <param name="line">The starting line</param>
/// <param name="column">The starting column</param>
/// <param name="tabWidth">The tab width</param>
public static System.Collections.Generic.IEnumerable<Token> Tokenize(<%=texttype%> text, long position = 0, int line = 1, int column = 1, int tabWidth = 4) {
<% } else {%>
public static System.Collections.Generic.IEnumerable<Token> Tokenize(<%=texttype%> text, long position = 0) {
<%}%>
    var sb = new System.Text.StringBuilder();
<%if(!reader) {%>
    var cursor = text.GetEnumerator();
<%}%>
    var cursorPos = position;
    var ch = _FetchNextInput(<%=curname%>);
<% if(lineCounted) {%>
    var lc = line;
    var cc = column;
<%}%>
    while (ch != -1) {
        sb.Clear();
        position = cursorPos;
<% if(lineCounted) {%>
        line = lc;
        column = cc;
<%}%>
        var done = false;
        var acc = -1;
        var state = 0;
        while (!done) {
            done = true;
            // state starts with accept 
            acc = _TokenizerDfa[state++];
            // next is the number of transitions
            var tlen = _TokenizerDfa[state++];
            for (var i = 0; i < tlen; ++i) {
                // each transition starts with the destination index
                var tto = _TokenizerDfa[state++];
                // next with a packed range length
                var prlen = _TokenizerDfa[state++];
                for (var j = 0; j < prlen; ++j) {
                    // then the packed ranges
                    var pmin = _TokenizerDfa[state++];
                    var pmax = _TokenizerDfa[state++];
                    if (ch >= pmin && ch <= pmax) {
<% if(lineCounted) {%>
                        switch(ch) {
                            case '\t':
                                cc = (((cc - 1) / tabWidth) + 1) * tabWidth + 1;
                                break;
                            case '\r':
                                cc = 1;
                                break;
                            case '\n':
                                ++lc;
                                cc = 1;
                                break;
                            default:
                                if (ch > 31) ++cc;
                                break;
                        }
<%}%>
                        sb.Append(char.ConvertFromUtf32(ch));
                        ch = _FetchNextInput(<%=curname%>);
                        ++cursorPos;
                        state = tto;
                        i = tlen;
                        done = false;
                        break;
                    }
                }
            }
        }
        if (-1 != acc) {
            var sacc = acc;
            // process block ends
            var blockEnd = _TokenizerBlockEndDfas[acc];
            if (blockEnd != null) {
                state = 0;
                while (ch != -1) {
                    done = false;
                    acc = -1;
                    while (!done) {
                        done = true;
                        // state starts with accept 
                        acc = blockEnd[state++];
                        // next is the number of transitions
                        var tlen = blockEnd[state++];
                        for (var i = 0; i < tlen; ++i) {
                            // each transition starts with the destination index
                            var tto = blockEnd[state++];
                            // next with a packed range length
                            var prlen = blockEnd[state++];
                            for (var j = 0; j < prlen; ++j) {
                                // then the packed ranges
                                var pmin = blockEnd[state++];
                                var pmax = blockEnd[state++];
                                if (ch >= pmin && ch <= pmax) {
<% if(lineCounted) {%>
                                    switch (ch) {
                                        case '\t':
                                            cc = (((cc - 1) / tabWidth) + 1) * tabWidth + 1;
                                            break;
                                        case '\r':
                                            cc = 1;
                                            break;
                                        case '\n':
                                            ++lc;
                                            cc = 1;
                                            break;
                                        default:
                                            if (ch > 31) ++cc;
                                            break;
                                    }
<%}%>
                                    sb.Append(char.ConvertFromUtf32(ch));
                                    ch = _FetchNextInput(<%=curname%>);
                                    ++cursorPos;
                                    state = tto;
                                    i = tlen;
                                    done = false;
                                    break;
                                }
                            }
                        }
                    }
                    if (-1 != acc && 0==(_SymbolFlags[sacc]&1)) {
<% if(lineCounted) {%>
                        yield return new Token(sacc, sb.ToString(), position, line, column);
<% } else { %>
                        yield return new Token(sacc, sb.ToString(), position);
<%}%>
                    }
<% if(lineCounted) {%>
                    switch (ch) {
                        case '\t':
                            cc = (((cc - 1) / tabWidth) + 1) * tabWidth + 1;
                            break;
                        case '\r':
                            cc = 1;
                            break;
                        case '\n':
                            ++lc;
                            cc = 1;
                            break;
                        default:
                            if (ch > 31) ++cc;
                            break;
                    }
<%}%>
                    sb.Append(char.ConvertFromUtf32(ch));
                    ch = _FetchNextInput(<%=curname%>);
                    ++cursorPos;
                    state = 0;
                }
                continue;
            } // if (blockEnd != null) ...
            else if (sb.Length > 0 && 0==(_SymbolFlags[acc]&1)) {
<% if(lineCounted) {%>
                yield return new Token(acc, sb.ToString(), position, line, column);            
<% } else { %>
                yield return new Token(acc, sb.ToString(), position);            
<%}%>
            }
        } 
        else {
            // handle the errors
            done = false;
            while (!done) {
                done = true;
                // state starts with accept 
                state = 1;
                // next is the number of transitions
                var tlen = _TokenizerDfa[state++];
                var matched = false;
                for (var i = 0; i < tlen; ++i) {
                    // each transition starts with the destination index
                    state++; // skip it
                    // next with a packed range length
                    var prlen = _TokenizerDfa[state++];
                    for (var j = 0; j < prlen; ++j) {
                        // then the packed ranges
                        var pmin = _TokenizerDfa[state++];
                        var pmax = _TokenizerDfa[state++];
                        if (ch >= pmin && ch <= pmax) {
                            state = 0;
                            i = tlen;
                            matched = true;
                            break;
                        }
                    }
                }
                if(!matched && ch!=-1) {
<% if(lineCounted) {%>
                    switch (ch) {
                        case '\t':
                            cc = (((cc - 1) / tabWidth) + 1) * tabWidth + 1;
                            break;
                        case '\r':
                            cc = 1;
                            break;
                        case '\n':
                            ++lc;
                            cc = 1;
                            break;
                        default:
                            if (ch > 31) ++cc;
                            break;
                    }
<%}%>
                    sb.Append(char.ConvertFromUtf32(ch));
                    ch = _FetchNextInput(<%=curname%>);
                    ++cursorPos;
                    done = false;
                } 
                else {
<% if(lineCounted) {%>
                    yield return new Token(ERROR, sb.ToString(), position, line, column);
<% } else { %>
                    yield return new Token(ERROR, sb.ToString(), position);
<%}%>
                    done = true;
                }
            }
        }    
    }
    yield break;
}
<%}%>

<%
var tokenizerBlockEndDfas = new int[blockEnds.Length][];
for(var i = 0;i<blockEnds.Length;++i) {
    tokenizerBlockEndDfas[i] = (blockEnds[i]!=null)?ToDfaTable(blockEnds[i]):null;
}

%>
static readonly int[] _TokenizerDfa = <%WriteCSArray(ToDfaTable(lexer),Response);%>

static readonly int[][] _TokenizerBlockEndDfas = <%WriteCSArray(tokenizerBlockEndDfas,Response);%>

static readonly int[] _SymbolFlags = <%WriteCSArray(symbolFlags,Response);%>