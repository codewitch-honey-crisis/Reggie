<%
var rules = (IList<LexRule>)Arguments["rules"];
var ignoreCase = (bool)Arguments["ignorecase"];
var lineCounted = (bool)Arguments["lines"];
var inputFile = (string)Arguments["inputfile"];
var outputFile = (string)Arguments["outputfile"];
var stderr = (TextWriter)Arguments["stderr"];
var codeclass = (string)Arguments["codeclass"];
var dot = (bool)Arguments["dot"];
var jpg = (bool)Arguments["jpg"];
var cwd = Path.GetDirectoryName(outputFile!=null?outputFile:inputFile);
var blockEnds = BuildBlockEnds(rules,inputFile,ignoreCase);
var symbolTable = BuildSymbolTable(rules);
var symbolFlags = BuildSymbolFlags(rules);
var lexer = BuildLexer(rules,inputFile,ignoreCase);
var dfa = ToDfaTable(lexer);
if(dot) {
    var opts = new F.FFA.DotGraphOptions();
    var fn = Path.Combine(cwd, codeclass + ".dot");
    stderr.WriteLine("Writing {0}...",fn);
    using(var sw=new StreamWriter(fn)) {
        lexer.WriteDotTo(sw,opts);
    }        
}
if(jpg) {
    var opts = new F.FFA.DotGraphOptions();
    var fn = Path.Combine(cwd, codeclass + ".jpg");
    stderr.WriteLine("Writing {0}...",fn);
    lexer.RenderToFile(fn,opts);
}
var dfaMap = GetDfaStateTransitionMap(dfa);
var isQ0reffed = IsQ0Reffed(dfa);
int si, sid;
int[][] blockEndDfas = new int[blockEnds.Length][];
//var hasBlockEnds = false;
for(var i = 0;i<blockEnds.Length;++i) {
    var be = blockEnds[i];
    if(be!=null) {
        blockEndDfas[i] = ToDfaTable(be);
       // hasBlockEnds = true;
    }
}
%>/// <summary>Represents a single token in a tokenized input stream</summary>
public struct Token
{
    /// <summary>Indicates the accepted symbol id</summary>
    public int Id { get; }
    /// <summary>Indicates the captured value</summary>
    public string Value { get; }
    /// <summary>Indicates the position within the stream</summary>
    public long Position { get; }
<%  if (lineCounted) {%>
    /// <summary>Indicates the line number within the stream</summary>
    public int Line { get; }
    /// <summary>Indicates the column number within the stream</summary>
    public int Column { get; }
<% } %>
    /// <summary>Constructs a new instance of a token</summary>
    /// <param name="id">The symbol id</param>
    /// <param name="value">The captured value</param>
    /// <param name="position">The position</param>
<%  if (lineCounted) {%>
    /// <param name="line">The line</param>
    /// <param name="column">The column</param>
    public Token(int id, string value, long position, int line, int column) {
<% } else { %>
    public Token(int id, string value, long position) {
<% } %>
        Id = id;
        Value = value;
        Position = position;
<%  if (lineCounted) {%>
        Line = line;
        Column = column;
<% } %>
    }
}
/// <summary>Indicates the #ERROR symbol id</summary>
public const int ERROR = -1;<%
foreach(var rule in rules) {%>
/// <summary>Indicates the <%=rule.Symbol%> symbol id</summary>
public const int <%=rule.Symbol%> = <%=rule.Id%>;<%
}
for(var k = 0;k<2;++k) { 
    bool reader = k==1;

    string curtype = reader ? "System.IO.TextReader":"System.Collections.Generic.IEnumerator<char>";
    string curname = reader ? "text":"cursor";
    string texttype = reader ? "System.IO.TextReader":"System.Collections.Generic.IEnumerable<char>";%>
/// <summary>Lexes tokens off of an input stream</summary>
/// <param name="text">The text to tokenize</param>
/// <param name="position">The starting position</param><% 
if(lineCounted) { %>
/// <param name="line">The starting line</param>
/// <param name="column">The starting column</param>
/// <param name="tabWidth">The tab width</param>
public static System.Collections.Generic.IEnumerable<Token> Tokenize(<%=texttype%> text, long position = 0, int line = 1, int column = 1, int tabWidth = 4) {<% 
} else {%>
public static System.Collections.Generic.IEnumerable<Token> Tokenize(<%=texttype%> text, long position = 0) {<%
}%>
    var sb = new System.Text.StringBuilder();<%
if(!reader) {%>
    var cursor = text.GetEnumerator();<%
} // if(!reader) ...%>
    var cursorPos = position;
    var ch = _FetchNextInput(<%=curname%>);<% 
if(lineCounted) {%>
    var lc = line;
    var cc = column;<%
} // if(lineCounted)... %>
    while (ch != -1) {
        sb.Clear();
        position = cursorPos;<% 
if(lineCounted) {%>
        line = lc;
        column = cc;<%
} // if(lineCounted) ...
si = 0;
sid = 0;
while(si<dfa.Length) {
    var sacc = dfa[si++];
    if(sid==0) {
        if(isQ0reffed) {%>
    q0:<%} else {%>
    // q0:<%
        } // if(isQ0reffed)...
    } else {%>
    q<%=sid%>:<%
    } // if(sid==0)
    var tlen = dfa[si++];
    for(var j=0;j<tlen;++j) {
        var tto = dfa[si++];
        var rstart = si;
        var ranges = dfa;
        if(lineCounted) {
            var lclist = new List<int>(10);
            if (DfaRangesContains('\n',ranges,rstart)) {
                lclist.Add('\n');
                ranges = DfaExcludeFromRanges('\n',ranges,rstart);
                rstart = 0;        
            }
            if (DfaRangesContains('\r',ranges, rstart)) {
                lclist.Add('\r');
                ranges = DfaExcludeFromRanges('\r',ranges,rstart);
                rstart = 0; 
            }
            if (DfaRangesContains('\t',ranges, rstart)) {
                lclist.Add('\t');
                ranges = DfaExcludeFromRanges('\t',ranges,rstart);
                rstart = 0;
            }
            if(lclist.Contains('\t')) {%>
        if(ch == '\t') {
            sb.Append(unchecked((char)ch));
            cc = (((cc - 1) / tabWidth) + 1) * tabWidth + 1;
            ch = _FetchNextInput(<%=curname%>);
            ++cursorPos;
            goto q<%=dfaMap[tto]%>;
        }<%
            }
            if (lclist.Contains('\r')) {%>
        if(ch == '\r') {
            sb.Append(unchecked((char)ch));
            cc = 1;
            ch = _FetchNextInput(<%=curname%>);
            ++cursorPos;
            goto q<%=dfaMap[tto]%>;
        }<%
            }
            if (lclist.Contains('\n')) {%>
        if(ch == '\n') {
            sb.Append(unchecked((char)ch));
            ++lc;
            cc = 1;
            ch = _FetchNextInput(<%=curname%>);
            ++cursorPos;
            goto q<%=dfaMap[tto]%>;
        }<%
            }
        }
        var exts = GetTransitionExtents(ranges,rstart);%>
        if(<%WriteCSRangeCharMatchTests(ranges, rstart, 2, Response);%>) {<%
        if(exts.Value<128) {%>
            sb.Append(unchecked((char)ch));<%} else {%>
            sb.Append(char.ConvertFromUtf32(ch));<%
        }
         if(lineCounted) {
            if(exts.Key>31) {%>
            ++cc;<%
            } else if(exts.Value>31) {%>
            if(ch > 31) ++cc;<%
            }
        }%>
            ch=_FetchNextInput(<%=curname%>);
            ++cursorPos;
            goto q<%=dfaMap[tto]%>;
        }<%
        // skip the packed ranges
        var prlen = dfa[si++];
        si+=prlen*2;
    } // for .. tlen
    if(sacc!=-1) { // accepting
        if(blockEnds[sacc]==null) {
            if(0==(symbolFlags[sacc]&1)) {
                if(lineCounted) {%>
        yield return new Token(<%=symbolTable[sacc]%>, sb.ToString(), position, line, column);<% 
                } else {%>
        yield return new Token(<%=symbolTable[sacc]%>, sb.ToString(), position);<%
                } // if(lineCounted)...
            } // if(0==(symbolFlags[sacc]&1))... %>
            continue;<%
        } else // if(blockEnds[sacc]...
        {
            if(lineCounted) {%>
            if(_Tokenize<%=symbolTable[sacc]%>BlockEnd(<%=curname%>,sb, ref cursorPos, ref lc, ref cc, tabWidth, ref ch)) {
                yield return new Token(<%=symbolTable[sacc]%>, sb.ToString(), position, line, column);<% 
            } else { // if(lineCounted)...%>
            if(_Tokenize<%=symbolTable[sacc]%>BlockEnd(<%=curname%>,sb, ref cursorPos, ref ch)) {    
                yield return new Token(<%=symbolTable[sacc]%>, sb.ToString(), position);<%
            }%>
            continue;
            }<% // if(_Tokenize...
            if(!lineCounted) {%>
            yield return new Token(ERROR, sb.ToString(), position);<%
            } else {%>
            yield return new Token(ERROR, sb.ToString(), position, line, column);<%
            }%>
            continue;<%
        } // if(blockEnds[sacc]...
    } else {// not accepting%>
        goto error;<%
    }
    ++sid; // we're on the next state now
} // while(si<dfa.Length) 
%>
    error:
        while(ch!=-1 && !(<%
var esi = 1;
var etlen = dfa[esi++];
for(var i = 0;i<etlen;++i) {
    ++esi;
    WriteCSRangeCharMatchTests(dfa, esi, 2, Response);
    if(i<etlen-1) {%> || 
        <%
    } // if(i<etlen-1) ...
    var plen = dfa[esi++];
    esi+=plen*2;
} // for(var i = 0;i<etlen;++i) ...
        %>)) {
            sb.Append(char.ConvertFromUtf32(ch));<%
if(lineCounted)
{%>
            switch(ch) {
            case '\t':
                cc = (((cc - 1) / tabWidth) + 1) * tabWidth + 1;
                break;
            case '\r':
                cc = 1;
                break;
            case '\n':
                cc = 1;
                ++lc;
                break;
            default:
                if(ch>31) ++cc;
                break;
            }<%     
} // if(lineCounted)...%>
            ch=_FetchNextInput(<%=curname%>);
            ++cursorPos;
        } <% // while(!..
if (!lineCounted) {%>
        if(sb.Length>0) yield return new Token(ERROR, sb.ToString(), position);<%
            } else {%>
        if(sb.Length>0) yield return new Token(ERROR, sb.ToString(), position, line, column);<%
} // if (!lineCounted) ... %>
    } <%// while(ch!=-1)...%>
} <% // Tokenize(...
foreach(var rule in rules) {
    var be = blockEnds[rule.Id];
    if(be!=null) {
        if(!lineCounted) {%>
static bool _Tokenize<%=rule.Symbol%>BlockEnd(<%=curtype%> <%=curname%>, System.Text.StringBuilder sb, ref long cursorPos, ref int ch) {<%
        } else { // if(!lineCounted) ...%>
static bool _Tokenize<%=rule.Symbol%>BlockEnd(<%=curtype%> <%=curname%>, System.Text.StringBuilder sb, ref long cursorPos, ref int lc, ref int cc, int tabWidth, ref int ch) {<%
        } // if(!lineCounted) ...%>
    ch = _FetchNextInput(<%=curname%>);
    while (ch != -1) {
        sb.Clear();<% 
si = 0;
sid = 0;
var bedfa = blockEndDfas[rule.Id];
var bedfaMap = GetDfaStateTransitionMap(bedfa);
var beQ0reffed = IsQ0Reffed(bedfa);
while(si<bedfa.Length) {
    var sacc = bedfa[si++];
    if(sid==0) {
        if(beQ0reffed) {%>
    q0:<%} else {%>
    // q0:<%
        } // if(beQ0reffed)...
    } else {%>
    q<%=sid%>:<%
    } // if(sid==0)
    var tlen = bedfa[si++];
    for(var j=0;j<tlen;++j) {
        var tto = bedfa[si++];
        var rstart = si;
        var ranges = bedfa;
        if(lineCounted) {
            var lclist = new List<int>(10);
            if (DfaRangesContains('\n',ranges,rstart)) {
                lclist.Add('\n');
                ranges = DfaExcludeFromRanges('\n',ranges,rstart);
                rstart = 0;        
            }
            if (DfaRangesContains('\r',ranges, rstart)) {
                lclist.Add('\r');
                ranges = DfaExcludeFromRanges('\r',ranges,rstart);
                rstart = 0; 
            }
            if (DfaRangesContains('\t',ranges, rstart)) {
                lclist.Add('\t');
                ranges = DfaExcludeFromRanges('\t',ranges,rstart);
                rstart = 0;
            }
            if(lclist.Contains('\t')) {%>
        if(ch == '\t') {
            sb.Append(unchecked((char)ch));
            cc = (((cc - 1) / tabWidth) + 1) * tabWidth + 1;
            ch = _FetchNextInput(<%=curname%>);
            ++cursorPos;
            goto q<%=bedfaMap[tto]%>;
        }<%
            }
            if (lclist.Contains('\r')) {%>
        if(ch == '\r') {
            sb.Append(unchecked((char)ch));
            cc = 1;
            ch = _FetchNextInput(<%=curname%>);
            ++cursorPos;
            goto q<%=bedfaMap[tto]%>;
        }<%
            }
            if (lclist.Contains('\n')) {%>
        if(ch == '\n') {
            sb.Append(unchecked((char)ch));
            ++lc;
            cc = 1;
            ch = _FetchNextInput(<%=curname%>);
            ++cursorPos;
            goto q<%=bedfaMap[tto]%>;
        }<%
            }
        }
        var exts = GetTransitionExtents(ranges,rstart);%>
        if(<%WriteCSRangeCharMatchTests(ranges, rstart, 2, Response);%>) {<%
        if(exts.Value<128) {%>
            sb.Append(unchecked((char)ch));<%
        } else {%>
            sb.Append(char.ConvertFromUtf32(ch));<%
        }
        if(lineCounted) {
            if(exts.Key>31) {%>
            ++cc;<%
            } else if(exts.Value>31) {%>
            if(ch > 31) ++cc;<%
            }
        }%>
            ch=_FetchNextInput(<%=curname%>);
            ++cursorPos;
            goto q<%=bedfaMap[tto]%>;
        }<%
        // skip the packed ranges
        var prlen = bedfa[si++];
        si+=prlen*2;
    } // for .. tlen
    if(sacc!=-1) { // accepting%>
        return true;<%
    } else {// not accepting%>
        sb.Append(char.ConvertFromUtf32(ch));<%
        if(lineCounted)
{%>
        switch(ch) {
        case '\t':
            cc = (((cc - 1) / tabWidth) + 1) * tabWidth + 1;
            break;
        case '\r':
            cc = 1;
            break;
        case '\n':
            cc = 1;
            ++lc;
            break;
        default:
            if(ch>31) ++cc;
            break;
        }<%     
} // if(lineCounted)...%>
        ch=_FetchNextInput(<%=curname%>);
        ++cursorPos;<%
        if(si<bedfa.Length) {%>
            continue;<%
        }
    }
    ++sid; // we're on the next state now
} // while(si<bedfa.Length) %>
    }
    return false;
}<%
    } // if(be!=null) ...
} // foreach(var rule in rules) ...%>
<%} // for(var k = 0;k<2;++k) ... %>
